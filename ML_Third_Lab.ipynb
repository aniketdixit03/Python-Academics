{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/parkinsons_updrs.data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.loc[:,[\"index\",\"subject#\",\"age\",\"sex\",\"test_time\",\"motor_UPDRS\",\"total_UPDRS\",\"Jitter(%)\",\"Shimmer\",\"NHR\",\"HNR\",\"RPDE\",\"DFA\",\"PPE\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(column=['motor_UPDRS','total_UPDRS','Jitter(%)','Shimmer','NHR','HNR','RPDE','DFA','PPE'], figsize=(20,20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the columns of the dataframe\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1.\n",
    "# Evaluate the interclass spread between the two classes in the dataset\n",
    "# using the following features: motor_UPDRS, total_UPDRS, Jitter(%), Shimmer, NHR, HNR, RPDE, DFA, PPE\n",
    "\n",
    "\n",
    "class1_data = np.array(data[data['subject#'] == 1])\n",
    "class2_data = np.array(data[data['subject#'] == 2])\n",
    "\n",
    "class1_centroid = np.mean(class1_data, axis=0)\n",
    "class2_centroid = np.mean(class2_data, axis=0)\n",
    "\n",
    "intraclass_spread_class1 = np.mean(np.linalg.norm(class1_data - class1_centroid, axis=1))\n",
    "intraclass_spread_class2 = np.mean(np.linalg.norm(class2_data - class2_centroid, axis=1))\n",
    "\n",
    "\n",
    "interclass_distance = np.linalg.norm(class1_centroid - class2_centroid)\n",
    "\n",
    "print('Class 1 Centroid:', class1_centroid)\n",
    "print('Class 2 Centroid:', class2_centroid)\n",
    "print('Intraclass Spread Class 1:', intraclass_spread_class1)\n",
    "print('Intraclass Spread Class 2:', intraclass_spread_class2)\n",
    "print('Interclass Distance:', interclass_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one feature vector\n",
    "feature_vector_1 = np.array(data['motor_UPDRS'])\n",
    "feature_vector_1 = feature_vector_1.reshape(-1, 1)\n",
    "\n",
    "feature_vector_2 = np.array(data['total_UPDRS'])\n",
    "feature_vector_2 = feature_vector_2.reshape(-1, 1)\n",
    "\n",
    "\n",
    "feature_vector_1.mean(axis=0)\n",
    "feature_vector_2.mean(axis=0)\n",
    "\n",
    "print('FV-1 >> Mean >> ', feature_vector_1.mean(axis=0))\n",
    "print('FV-2 >> Mean >> ', feature_vector_2.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_vector_1 = np.mean(feature_vector_1, axis=0)\n",
    "centroid_vector_2 = np.mean(feature_vector_2, axis=0)\n",
    "\n",
    "print('FV-1 >> Centroid >> ', centroid_vector_1)\n",
    "print('FV-2 >> Centroid >> ', centroid_vector_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intraclass_spread_1 = np.mean(np.linalg.norm(feature_vector_1 - centroid_vector_1, axis=1))\n",
    "intraclass_spread_2 = np.mean(np.linalg.norm(feature_vector_2 - centroid_vector_2, axis=1))\n",
    "\n",
    "print('FV-1 >> Intraclass Spread >> ', intraclass_spread_1)\n",
    "print('FV-2 >> Intraclass Spread >> ', intraclass_spread_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interclass_distance = np.linalg.norm(centroid_vector_1 - centroid_vector_2)\n",
    "\n",
    "print('Interclass Distance:', interclass_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A2.\n",
    "\n",
    "# data\n",
    "\n",
    "num_bins = 10\n",
    "hist, bins = np.histogram(data['motor_UPDRS'], bins=num_bins)\n",
    "\n",
    "mean = np.mean(data['motor_UPDRS'])\n",
    "variance = np.var(data['motor_UPDRS'])\n",
    "\n",
    "#plot histogram\n",
    "plt.hist(data['motor_UPDRS'], bins=num_bins, alpha=0.5, color='blue', edgecolor='black')\n",
    "plt.xlabel('motor_UPDRS')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of motor_UPDRS')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "print(\"Mean >> \", mean)\n",
    "print(\"Variance >> \", variance)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A3. Take any two feature vectors from your dataset. Calculate the Minkwoski distance with r from 1 \n",
    "# to 10. Make a plot of the distance and observe the nature of this graph.\n",
    "\n",
    "vector1 = np.array(data['motor_UPDRS'])\n",
    "vector2 = np.array(data['total_UPDRS'])\n",
    "\n",
    "r_values = range(1, 11) # r = 1 to 10\n",
    "\n",
    "distance = [distance.minkowski(vector1, vector2, p=r) for r in r_values]\n",
    "\n",
    "plt.plot(r_values, distance, marker='o', linestyle='-')\n",
    "plt.xlabel('r')\n",
    "plt.ylabel('Minkowski Distance')\n",
    "plt.title('Minkowski Distance vs. r')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.iloc[:, 2:13].values\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "# X = data[['subject#', 'age', 'sex', 'test_time', 'Jitter(%)', 'Shimmer', 'NHR', 'HNR', 'RPDE', 'DFA', 'PPE']]\n",
    "# y = data['motor_UPDRS']  # Change 'motor_UPDRS' to 'total_UPDRS' if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Train a kNN classifier (k =3) using the training set obtained from above exercise. Following code \n",
    "# for help: \n",
    "# >>> import numpy as np \n",
    "# >>> from sklearn.neighbors import KNeighborsClassifier \n",
    "# >>> neigh = KNeighborsClassifier(n_neighbors=3) \n",
    "# >>> neigh.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A5. \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a6.\n",
    "# Test the score\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A7. \n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A8. \n",
    "# Make k = 1 to implement NN classifier and compare the results with kNN (k = 3). Vary k from 1 to \n",
    "# 11 and make an accuracy plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = KNeighborsClassifier(n_neighbors=1)\n",
    "model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary k from 1 to  11 and make an accuracy plot.\n",
    "k_values = range(1, 12)\n",
    "\n",
    "accu_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    accu_scores.append(accuracy)\n",
    "\n",
    "#plot the accuracy graph\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(k_values, accu_scores, marker='o', linestyle='--')\n",
    "plt.title('Accuracy vs. K Value')\n",
    "plt.xlabel('K values')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A9.\n",
    "# Please evaluate confusion matrix for your classification problem. From confusion matrix, the \n",
    "# other performance metrics such as precision, recall and F1-Score measures for both training and test \n",
    "# data. Based on your observations, infer the models learning outcome (underfit / regularfit / overfit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "confusion_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# precision, recall and F1-score for training data\n",
    "precision_train = precision_score(y_train, y_train_pred, average='micro')\n",
    "recall_train = recall_score(y_train, y_train_pred, average='micro')\n",
    "f1_score_train = f1_score(y_train, y_train_pred, average='micro')\n",
    "\n",
    "# precision, recall and F1-score for test data\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_pred, average='micro')\n",
    "recall_test = recall_score(y_test, y_test_pred, average='micro')\n",
    "f1_score_test = f1_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "#print the confusion matrix and other metrics\n",
    "print('Confusion Matrix - Training Data')\n",
    "print(confusion_matrix_train)\n",
    "print('Precision - Training Data', precision_train)\n",
    "print('Recall - Training Data', recall_train)\n",
    "print('F1 score - Training Data', f1_score_train)\n",
    "\n",
    "print('Confusion Matrix - Test Data')\n",
    "print(confusion_matrix_test)\n",
    "print('Precision - Test Data', precision_test)\n",
    "print('Recall - Test Data', recall_test)\n",
    "print('F1 score - Test Data', f1_score_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
