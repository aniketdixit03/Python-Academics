{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b7023a",
   "metadata": {},
   "source": [
    "### A1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "debc0d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('Lab Session2 Data.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "reports = df['Report'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1247a05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize the reports for all students\n",
    "tokenized_reports = [word_tokenize(report) for report in reports]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d371f47",
   "metadata": {},
   "source": [
    "### A2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "925d26ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'d\", \"'s\", \"'ve\", '(', ')', ',', '.', '..', '.Also', '.This', '/improve', '0.98', '0.ninety', '1.In', '124', '1550.7060.', '1560.6634', '16', '1698.9526', '1980s']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Merge all the tokenized reports into a single list\n",
    "merged_tokens = [token for report_tokens in tokenized_reports for token in report_tokens]\n",
    "\n",
    "# Step 2: Remove duplicates to get distinct tokens (token population)\n",
    "token_population = list(set(merged_tokens))\n",
    "\n",
    "# Sort the token population alphabetically if needed\n",
    "token_population.sort()\n",
    "\n",
    "# Print the first 20 tokens as an example\n",
    "print(token_population[:20])\n",
    "\n",
    "# You now have the token population containing all distinct tokens from all documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0244c",
   "metadata": {},
   "source": [
    "### A3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f79b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Get the list of English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Print the first few stop words\n",
    "print(list(stop_words)[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ab3bb",
   "metadata": {},
   "source": [
    "### A4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96364b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a token_population list created as mentioned earlier\n",
    "\n",
    "# Remove stop words from the token population\n",
    "token_population_without_stopwords = [word for word in token_population if word.lower() not in stop_words]\n",
    "\n",
    "# Create a Bag-of-Words representation for the token population\n",
    "bag_of_words_token_population = {}\n",
    "for word in token_population_without_stopwords:\n",
    "    if word in bag_of_words_token_population:\n",
    "        bag_of_words_token_population[word] += 1\n",
    "    else:\n",
    "        bag_of_words_token_population[word] = 1\n",
    "\n",
    "# Print the Bag-of-Words representation for the token population\n",
    "print(bag_of_words_token_population)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b5363",
   "metadata": {},
   "source": [
    "### A5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce4eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
